---
layout: post
title:  "KDLP - Part 1"
date:   2024-06-30 19:59:45 +0300
categories: jekyll update
---

**Contents**
* TOC
{:toc}
## Lecture 6

This lecture deals with execution contexts, and syscalls internals in particular. \
For x86-32, the syscall request is being issued via `int 0x80`, hence involves dereference of `IDT[0x80]`. For x86-64, `syscall` is used. For arm64, `svc`. \
If we would issue `msr VBAR_EL1, x0` from userspace, the program shall crash with an "illegal instruction". `msr` reads from model-specific register, into the second operand, `x0` in this case. Indeed, `VBAR_EL1` serves as the specific reg - vector base address register, execution level 1. Hence, by trying to access a register that belongs to execution level 1 from userspace, the kernel terminates our process. 

### Execution Context

Just CPU registers state. Hence, context === all registers values. \
For example, `setjmp(3)` saves the current state of the program, while `longjmp(3)` restores it. \
Another example are usermode threads. Recall they share heap, code, data - while having their own stack and registers. 

### Kernelspace and userspace

The main difference is their privilege level. \
An important simplification - kernelspace execution context can be subdivided, to code that *runs on behalf of a particular userspace process*, or *code that runs on its own behalf* (for example, kthreads or interrupt handlers). \
Context switch is capture of the current CPU regs state, and load of the previously-saved CPU regs. \
Kernel context switch is just as a regular processes context switch, but also changes the privileges. 

### Re-entrancy

If multiple invocations of a function can safely run concurrently, it is considered as reentrant. \
On single threaded usermode, this term may be used within signal handlers. \
If there's at least one non-reentrant call within a function, it is considered as non-reentrant at all.


### task_struct

Linux's PCB, defined within `include/linux/sched.h`. \
Each `pid` is mapped to a unique `task_struct`. \
In particular, `current` denotes the `task_struct` of process in current execution context. Notice it can also refer to the currently running kernel thread. \
Moreover, we cant always rely on this - as there are kernel contexts that dont have any process attached. \
Its implementation is architecture-specific.

### pid, tid, tgpid

When we refer to kernelspace `pid`, we actually mean `tid` within userspace. When we refer to kernelspace `tgid`, we actually mean userspace `pid`. \
We can learn this by looking at `getpid, gettid` syscalls within `kernel/sys.c`, defined via `SYSCALL_DEFINE0` (as it takes 0 arguments). \
Interesting to note, is that `getpid` takes namespaces into account, as well as locking. If we would call `getpid` from a container (having `/bin/sh` as its initial process), we should get `pid = 1`. 

Why's there a distinguish between `pid` and `tgid` though? \
Before Linux 2.6, there were only `pid`s. We could share address space between processes via `clone`, which allowed thread-like behavior. However, these processes were too independent (no shared signals for example). Hence, `tgid` was introduced. It required both kernel and userspace changes: \
For userspace, C library was now hardened for concurrency, and introduced `tid` concept to subdivide `pid` (as the term `pid` was already used). \
For kernelspace, `tgid` concept was introduced, as threads were already implemented in the kernel. To implement group of threads, which is what processes are, `tgid` was used - which groups kernel `pid`s together. 

### Syscalls 

`strace` is an awesome tool, which traces system calls as well as signals. It can also show the resources limits of a process.  

We'd like syscalls to be both fast and secured. Spectre is an example of that tradeoff implications - speculating both sides of an `if` statement, a speed optimization, while leaving side channels implications (cache memory changes) that could lead to information disclosure. \
Moreover, we'd like them to be stable and re-entrant. The kernel code must be reentrant. 

Regarding security, userspace-kernelspace is a classic scenario of the "Confused deputy problem", where an unprivileged entity may perform requests towards some privileged entity. \
A classic example is using the exposed userspace's syscalls API, and sending arbitrary values for pointers arguments. The kernel have to validate the address range of any pointer arguments, and making sure that they belong to the requested process!

## Lecture 7

Deals with syscalls implementation on arm64 and x86-64. 

### Syscall Implementation

Userspace invocation, HW PE, kernel code handler, HW PD, userspace continuation. \
We can see `/proc/PID/syscall`, which is the current syscall and arguments a process is running. 

For usespace invocations, we usually use library wrappers, as provided by `libc`. This saves overhead of calls, and avoids arch specific details. We can use `ltrace` to trace library calls. \
Notice each arch have its own implementation of user library. For example, in order to use syscalls within arm64, we have to specific sysnum in `x8`, args in `x0-x5`, and `svc #0` to invoke it. For x86-64, this differs. 

HW privilege escalation on arm64 is performed via `__primary_switched`, which is called early on the kernel boot time. This function loads the vector table address into model-specific register `VBAR_EL1`. In a similar manner, x86-64 sets `MSR_LSTAR` to `entry_SYSCALL_64` address, within `syscall_init`. \
Notice exception levels on ARM are the reverse-order of privileges rings within x86. Both archs contains this level within an arch-specific register (`cs` in x86).

Most kernel handlers starts with some arch specific low-level asm and C macros. Higher on the stack, there's more generic code. \
Within arm64, HW jumps to a specific offset in `vectors`, as defined by `VBAR_EL1`. The "classic" entry would be sync 64-bit EL0 call (in case it was issued from userspace). This would trigger `el0t_64_sync_handler`, which would usually trigger `el0_svc`. This method does multiple interesting things, including the swap from usermode to kernelmode, arch specific stuff, execution of the syscall via `do_el0_svc`, and finally returning to userspace. Notice `do_el0_svc` actually loads the syscall table to `el0_svc_common`, which internally executes the call. \
For arm64, upon completion, the kernel returns via `ret_to_user`, which calls `kernel_exit 0`, which eventually calls `eret`. x86-64 uses `sysret` or `iret`. \
The kernel stores the real error code within `errno`, which is located at userspace thread-local memory area. 

## Lecture 8

BPF - BSD packet filter. Also deals with `bpftrace`. \
A way for the users to upload executable code to the kernel, and run it within the kernel. This code have to be verified. 

### BPF

Originally, used for a packet filter. \
Nowadays it stands for in-kernel general purpose VM. 
The main issue with modules, is that those are written in C, not having any verifications being performed on the imported kernel code. \
It uses verified JIT compilation from C to BPF to native code. 

### BPF Main Features

Tracing & observability, runtime verifications, as well as event-driven programming rather than task-driven (using probes). \
Safety, as when a module crashes - the kernel crashes. When a BPF crashes, nothing happens. 

Networking example is `XDP` (express data path) - optimizes network operations in kernel. \
Profiling example is `perf`, which also uses the BPF subsystem. 

### kprobes

Dynamic kernel code instrumentation. 

1. First byte of instruction can be replaced with breakpoint (similar to `ftrace`). At the beggining of functions to-be-instrumented, kernel code is compiled to have `noop` instructions, that can be replaced with `jmp`s at runtime (to some code snippet that stores information within a buffer), and jump back to continue the function's flow. 

2. For function return, uses `kretprobes`, which is a similar concept. 

For example, in order to trace `do_nanosleep`, defined at `kernel/time/hrtimer.c`, we'd first have to download `bpftrace` via `sudo dnf install -y bpftrace`, which now resides under `/bin/bpftrace`. \
Afterwards, we'd like to verify the available probes contains `kprobe:do_nanosleep`:

```bash
$ sudo bpftrace -l | grep do_nanosleep
kfunc:vmlinux:do_nanosleep
kprobe:do_nanosleep
```

Notice `kfunc` is a BPF kernel function, meaning it is exposed for use by BPF program, and is part of the `vmlinux` binary. See more of [this][kfuncs].

We shall install the following 2 probes, by executing `sudo ./nanosleep.bp`:

```bash
#!/bin/bpftrace

BEGIN {
    printf("Ahoy!\n");
}

kprobe:do_nanosleep {
    printf("PID %d (%s) sleeping\n", pid, comm);
}
```

Now we've actually installed an extra code snippet that would be executed upon every invocation of `do_nanosleep`! \
Notice we would do a similar probe tracing the return value, via `kretprobe:do_nanosleep`, denoted via `retval`. 

### uprobes

Userspace program instrumentation this time. \
For example, tracing bash's `readline` function, within `readline.bp`:

```bash
#!/bin/bpftrace

uprobe:/bin/bash:readline {
    printf("%s %d %s\n", comm, arg0, str(arg0));
}
```

### tracepoints

Statically defined, giving some stable interface. \
For example, compiling the kernel via `CONFIG_HAVE_SYSCALL_TRACEPOINTS`. \
Indeed, `SYSCALL_DEFINEx` contains a call for `SYSCALL_METADATA` macro, which wraps the code of the tracepoints invocation. \
We shall find the desired tracepoint:

```bash
$ sudo bpftrace -l | grep tracepoint | grep open
tracepoint:syscalls:sys_enter_openat
```

And install our probe:

```bash
#!/bin/bpftrace

tracepoint:syscalls:sys_enter_openat {
    printf("%d %s %s\n", pid, comm, str(args.filename));
}
```

### BCC

BPF compiler collection, set of many important tools and libraries. These are the "heavy guns" we'd use. \
For example, `opensnoop.py` is an optimized implementation of the above `open` tracing functionality. 

### bpftrace

Simple, lightweight option, less featured than `BCC`. \
For example, `bpftrace/tools/opensnoop.bt`. \
Its syntax is similar to `awk`. 

Notice we can use bpftrace maps, denoted by `@`, and used as key-value storage. \
For example, per-process syscall histogram:

```bash
#!/bin/bpftrace

tracepoint::raw_syscalls::sys_enter {
    @[comm] = count();
}
```

We can only assign the special function `count` to a map, which serves as an histogram method.

Another example, histogram of bytes read for a specific pid:

```bash
tracepoint::syscalls::sys_exit_read /pid == $1/
{
    @bytes = hist(args.ret);
}
```

We use `pid` as a filter. `bytes` serves as the named map. 

Another important feature of `bpftrace` is using the live stacks builtins - `kstack` and `ustack`. \
For example:

```bash
kprobe::ksys_read {
    printf("stack:%s\n", kstack);
}
```

Dumping the kernel / user stack layout. 

Notice: `bpftrace` reads on a per-cpu basis! Hence, messages may seem out-of-order. 

### BPF Compilation

A `bpftrace` program is compiled to AST, then to LLVM IR, and finally to BPF bytecode, which is JIT'ed to machine code. \
The bpf parser and lexer can be found under `bpftrace` repo. \
Interestingly, we can use `bpftrace -d` option, which also generates the AST and LLVM output. 

The load of the BPF program is actually being made using the `bpf` syscall, which receives within its first parameter a command code. For example, `BPF_PROG_LOAD`. 

### BPF JIT

All BPF programs are JITed. There used to be an option to interpret the program, without first compiling to machine code. It got removed for security reasons (and JIT is significantly faster..)

### In-kernel Verification

Hundreds of possible error returns, under `kernel/bpf/verifier.c`. 

We can see all of the currently-installed BPF programs via:

```bash
sudo bpftool prog show
```

We can also parse its translated bytecode via `prog dump xlated id <id>`.

### BPF - Kernel Entry Points

For example, `BPF_CALL_0(bpf_get_current_pid_tgid)`, called upon retrieving the `pid` or `tgid` from the added probe. \
Other interesting files to look at, are `include/uapi/linux/bpf.h` and `filter.h`, `bpf_common.h`. 

### unlikely macro

Compiler optimization macro (serves as an hint for branch). 
Defined within `include/linux/compiler.h`. 

### Further reading

We can learn more about BPF by reading the bpftrace kselftests (good place to start contributing to the kernel), as well as reading the `BPF Performance Tools` book. 


## E1

## P1

[kfuncs]: https://docs.kernel.org/bpf/kfuncs.html
