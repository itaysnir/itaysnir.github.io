---
layout: post
title: "CVE-2021-0920 - Tiny Kernel Window Exploitation"
date: 2025-04-30 21:59:45 +0300
categories: jekyll update
---

**Contents**
* TOC
{:toc}
## Introduction

This article demonstrates how to exploit a very tiny kernel race window, even on non-preemptive kernels. My personal goal is to learn from it, and possibly appliying it to my own kernel exploit. \
The key idea is to run an interrupt handler within the small window (by making `timerfd` to expire), and to make sure the wakeup have to churn through lots of waitqueue items. 

All credits goes to [this project zero document][project-zero-doc]. 


## Bug Overview

UNIX domain sockets allows passing fds using `SCM_RIGHTS`. Because reference loops may be created, the kernel offers a GC logic, specifically for UNIX domain sockets. In particular, it compares the file's refcount with the number of *total references from inflight SKBs*. In case of equiality, the UNIX domain socket subsystem owns exclusive access to the file. \
Apparently, `struct file` can be referenced from RCU read-side critical section (which doesn't increases the file's refcount). This RCU reference can be upgraded into refcounted reference via `get_file_rcu, get_file_rcu_many`. \
For example, the `dup` syscall - would install the resulting reference within the FD table.

When the GC thinks it has exclusion access to file, it performs operations that violate the regular locking rules. In particular, while `recvmsg` assumes that queued SKBs can only be removed under `->iolock`, the GC mechanism doesn't assumes it. \
This means that for refcounted objects (which are all RCU-accessible) there are 2 possible states: `live`, and `owned by GC`. There was a race when the file ref went down to zero - which would be exclusively owned by the GC subsystem, while being still reference-ably by calling `get_file_rcu`. 

### The Race

In the middle `of __fget_files` (can be triggered via `dup`) - between the fd lookup, and its refcount increment:

```c
static struct file *__fget_files(struct files_struct *files, unsigned int fd,

                                 fmode_t mask, unsigned int refs)
{
        struct file *file;
        rcu_read_lock();
loop:
        file = files_lookup_fd_rcu(files, fd); // race window start
        if (file) {
                /* File object ref couldn't be taken.
                 * dup2() atomicity guarantee is the reason
                 * we loop to catch the new file (or NULL pointer)
                 */
                if (file->f_mode & mask)
                        file = NULL;
                else if (!get_file_rcu_many(file, refs)) // race window end - increments the refcount
                        goto loop;
        }
        rcu_read_unlock();
        return file;
}
```

Within this window, if we'd drop the file's reference count to `0` and run `unix_gc` (such that the UNIX domain socket subsystem would think it exclusively owns that file), we'd win the race. \
By inspecting the disassembly of `amd64`, this results with ~12 instructions. 

## Cache Misses

Because the small window actually performs the first dereference of `struct file->f_mode`, we may use eviction pattern / dirty cacheline on another core. \
To do it, we would like to temporarily bump the refcount of the file up and down, on another CPU. This can be done by executing `close(dup(fd))` within a loop, or just accessing the `fd` many times from a multithreaded process. Notice we'd like for the cache miss to occur only when we hit the race window, not before. To prevent it - we can call `dup` with a different FD number as warm up, before running the race. Moreover, this FD number must be within the same cacheline as the target FD's cacheline within the fd table, such that it would be already hot. 

## CONFIG_PREEMPT - Invoking the Scheduler via IPI

On Android, `CONFIG_PREEMPT` allows abusing the scheduler to interrupt the execution. For example, giving low scheduler priority to the target thread, and to pin it to a specific CPU core - together with an high-priority thread that is blocked on a `read` syscall (or empty `pipe`, or `eventfd`). \
Upon writing to the pipe, the high-priority thread becomes schedulable - and IPI would be sent to the target CPU core to wake it up and enter the scheduler. \
The problem is that it would be challenging to peempt the victim thread in the exact right spot. 

## HRTimers

A better way to trigger the scheduler - instead of an IPI from a different core, using an expiring high-resolution timer on the same core. \
`hrtimers`  are exposed through few userspace APIs. In particular, timeout of `select, pselect` uses `hrtimer`. \
The reason these timers are "high resolution" is that they utilize the expiration time of the next `hrtimer` on the CPU core, which is programmed to the hardware timer. This means that by writing `hrtimer` via `timer_settime, timerfd_settime`, the HW would raise an interrupt at the expiration time!

## No CONFIG_PREEMPT kernels

In that case, triggering hrtimer won't just immediately enter the scheduler and preempt the thread. But instead of using that clock interrupt for peemption, we can make the interrupt handler run for a very long time. \
`timerfd` is a fd that refers to a timer. For example, calling `read` on timerfd would block until the timer expires. Same as `epoll`- which would show up the timerfd as readable only when the timer expires. \
In case of a ready timerfd, all of its waiters (including `epoll` watches), which are queued up in a linked list, are waken up via `wake_up`. If we'd make that list extremely long, the interrupt handler will have to spend a lot of time iterating that list. \
Its fairly easy to add tons of entries via `epoll` - which ties its watches to specific fd. Lets say we'd duplicate `fd` with hundreds of `dup` calls - a single `epoll` instance would install hundreds of waiters on that file. Hence, `500` epoll instances and `100` duplicated fds would result with `50000` waitqueue items. \
This results with ~30% chances of winning the race for this vuln

## Exploitation

`recvmsg` path assumes that SKBs on the receive queue are saved from deletion, due to the usage of the socket mutex. However, the GC may delete an SKB under the hood. We'd:

1. Start `recvmsg` call that looks up victim SKB, and block until the GC frees that SKB. 

2. Let `recvmsg` continue, operate on a freed SKB. 

Once way we can slow down `unix_gc` is by creating lots of sockets not directly referenced from the FD table, and have many tiny SKBs queued up. \
Moreover, we might be able to use `userfaultfd` to make `recv `run on the right timing. 

To prove we've triggered the UAF successfully, we should add the kernel command line flag `slub_debug=FP` (poisoning + sanity checks).

## Userfaultfd

Pretty wierd syscall - allows userspace to take responsibility for handling page faults. Very handy for kernel exploitation, lol. \
This syscall returns a fd that can be used for control over memory management. Using `ioctl` calls, a page fault within the desired userspace range will generate an event, that can be read from the file descriptor. The **process** can read the event, and take whatever action. \
This is intended to be used within multi-threaded process - one thread takes on the fault-handling task. A classic real-world usage of it is live-migration of a process from one machine to another. By doing so, the process can be moved and restarted on the new system **while leaving most of its memory behind - the pages it needs immediately can be demand-faulted across the net, driven by `userfaultfd` events**. \
In particular, **since the kernel waits for a response from the user-space handler to resolve a fault, page faults can cause an indefinite delay in the execution of the affected process**. This is always the cause, but usually the kernel controls the time it takes to resolve the fault - but not with `userfaultfd`, where the handler is under the process's direct control. Taking this even further, some page faults may be generated in the kernel - for example, when the kernel tries to access a userspace page during syscall handler (via `copy_from_user` for example). \
By doing so, the execution in the kernel might block at a known point, for a period of time that is under the process's control. 

**TL;DR: `userfaultfd` allows blocking a kernel context from userspace, for a userspace-controlled amount of time**

Further reading: FUSE, slow disk access


[project-zero-doc]: https://googleprojectzero.blogspot.com/2022/03/racing-against-clock-hitting-tiny.html
