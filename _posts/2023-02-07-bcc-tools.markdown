---
layout: post
title:  "BCC Tools"
date:   2023-02-07 19:59:43 +0300
categories: jekyll update
---

**Contents**
* TOC
{:toc}
## General

eBPF is pretty OP. \
It allows to run sandboxed programs in the kernel, that can be used for cool stuff, such as syscall filtering, tracing, and network filtering (probably the most trivial usage).

Due to its complexity, there are few projects that offer abstraction layers over eBPF - and [BCC][bcc-git] is one of them. 

BCC (BPF Compiler Collection) is a python library that makes it easy to write eBPF code. \
The callback functions should be written in C, and the pythonic API allows easy hooking of these probes to specific kernel events. 

Extra links for reading: [link0][link0] [link1][link1] [link2][link2] [link3][link3], [linux-performance][linux-performance] and [more-performance][more-performance].

## Installation

Installation from upstream sources requires some dependencies, such as LLVM with BPF support, Clang, cmake. 

```bash
# For Jammy (22.04)
sudo apt install -y bison build-essential cmake flex git libedit-dev \
libllvm14 llvm-14-dev libclang-14-dev python3 zlib1g-dev libelf-dev libfl-dev python3-distutils

git clone https://github.com/iovisor/bcc
mkdir bcc/build; cd bcc/build
cmake ..
make
sudo make install
cmake -DPYTHON_CMD=python3 .. # build python3 binding
pushd src/python/
make
sudo make install
popd
```

In order to verify the installation, simply run `execsnoop.py` tool. \
This tool traces over new processes that are being `exec`'ed within the system:

```bash
PCOMM            PID     PPID    RET ARGS
ls               7764    2652      0 /usr/bin/ls --color=auto -alF
```

Another simple option, is to download the binaries directly from the ubuntu package manager. \
However, note that many BCC tools may be outdated:

```bash
sudo apt install bpfcc-tools
```

The tools are installed under `/sbin` or `/usr/sbin`, and would end with a `-bpfcc` suffix. 

## Tutorial

### Basic Linux Performance Analysis

First, install the `sysstat` package. \
The following commands are very handy for basic analysis:

```bash
uptime
dmesg | tail
vmstat 1
mpstat -P ALL 1
pidstat 1
iostat -xz 1
free -m
sar -n DEV 1
sar -n TCP,ETCP 1
top
```

#### uptime

Quick way to view the average load (number of processes wanting to run on each core). \
Note these values also includes processes blocked in  uninterruptible I/O (such as disk / network). 

```bash
$ uptime
09:37:21 up 2 min,  4 users,  load average: 1.05, 0.82, 0.34
```

The above means a sum average over the last 1, 5 and 15 minutes, of processes waiting to run on each core (the above snapshot was taken shortly after system boot). 

#### dmesg

Shows system messages. 

#### vmstat 1

Basically parses `/proc/vmstat`. \
The `1` argument means to run within 1 second summaries. 

```bash
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0  17768  78428  32504 721608    0   12   688    54  173  264  4  7 89  1  0
 0  0  17768  78428  32512 721608    0    0     0    16  183  250  0  0 100  0  0
 0  0  17768  78428  32512 721608    0    0     0     4  134  197  0  0 100  0  0
```

`r` stands for the number of processes running on CPU, waiting to run. Note it *does not include I/O blocked processes*. \
Therefore, `r` value greater than the number of cores, means a saturation. 

`free` means the free memory (KB). 

`si, so` means swap in and swapped out pages. Non-zero values of these, means system runs out of memory. 

`us,sy,id,wa,st` means breakdowns of CPU time, taken as an average across all CPUs. User time, system time, idle, wait I/O time, and stolen time (by other guests). \
These counters may easily confirm if the CPU is busy. 

#### mpstat -P ALL 1

```bash
Linux 5.15.0-58-generic (itay-virtual-machine)  02/10/2023      _x86_64_        (4 CPU)

09:51:53 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
09:51:54 AM  all    0.00    0.00    0.76    0.00    0.00    0.51    0.00    0.00    0.00   98.74
09:51:54 AM    0    0.00    0.00    1.98    0.00    0.00    1.98    0.00    0.00    0.00   96.04
09:51:54 AM    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
09:51:54 AM    2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
09:51:54 AM    3    0.00    0.00    1.02    0.00    0.00    0.00    0.00    0.00    0.00   98.98
```

Prints CPU time breakdowns per CPU within the system. \
Can be used to check for an imbalance. 

#### pidstat 1

```bash
Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:        0        14    0.00    0.49    0.00    0.00    0.49     -  rcu_sched
Average:      108       643    0.00    0.49    0.00    0.00    0.49     -  systemd-oomd
Average:        0       726    0.49    0.00    0.00    0.00    0.49     -  vmtoolsd
Average:     1000      1723    0.49    0.00    0.00    0.00    0.49     -  node
Average:     1000      1845    0.00    0.49    0.00    0.00    0.49     -  node
Average:     1000      2037    0.00    0.49    0.00    0.00    0.49     -  vmtoolsd
Average:     1000      3850    1.97    3.45    0.00    0.00    5.42     -  pidstat
```

Pretty similar to `top`, but doesn't clears the screen. \
Might be nice to see %CPU usage of each process. 

Note that 100% CPU usage means 1 core. \
This means that usage of 1500% CPU, for example, meaning a process takes about 15 cores. 

#### iostat -xz 1

```bash
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.36    0.62    2.40    0.20    0.00   95.42

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
loop0            0.03      0.26     0.00   0.00    0.84     7.73    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop1            0.01      0.01     0.00   0.00    0.14     1.21    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop10           0.03      0.26     0.00   0.00    1.60     8.09    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
loop11           0.95     35.58     0.00   0.00    1.05    37.44    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.47
loop12           0.01      0.04     0.00   0.00    0.95     2.70    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop13           0.02      0.18     0.00   0.00    0.69     8.24    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
loop14           0.01      0.01     0.00   0.00    0.00     1.27    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop2            0.27      3.44     0.00   0.00    1.41    12.62    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.09
loop3            0.04      0.80     0.00   0.00    1.42    20.45    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
loop4            0.05      0.83     0.00   0.00    2.16    18.31    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
loop5            0.04      0.79     0.00   0.00    2.32    19.12    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
loop6            0.81      9.45     0.00   0.00    1.08    11.71    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.14
loop7            0.44      4.64     0.00   0.00    0.60    10.53    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.05
loop8            0.04      0.27     0.00   0.00    1.46     7.54    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
loop9            0.03      0.26     0.00   0.00    2.14     8.14    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
sda             22.19    890.83     8.49  27.68    1.27    40.14    8.37    428.97    24.23  74.32    1.51    51.24    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.04   3.18
sr0              0.07      1.55     0.00   0.00    0.86    23.28    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
sr1              0.07      1.56     0.00   0.00    1.47    21.20    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.02
```

Great tool to understand block devices. \
All block devices of the system are analyzed. 

`r/s, w/s, rkB/s, wkB/s` - Those are the delivered reads / writes to a device. 

`await` - avarage I/O time. Include both time queued and time serviced. 

`avgqu-sz` - average requests number, issued to the device. 

`%util` - The busy percent of the device. Very close to 100% usually means saturation. 

#### free -m

```bash
total        used        free      shared  buff/cache   available
Mem:            1941        1098          97           6         745         667
Swap:           6045          70        5975
```

`buffers` - The buffer cache, used for block device I/O. \
`cached` -The page cache, used by file systems. 

We want to make sure these aren't near-zero in size. 

Note the cached memory can be easily reclaimed, and therefore might be treated as `free`. [free-confusion][free-confusion]

#### sar -n DEV 1

```bash
10:07:16 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
10:07:17 AM        lo      2.00      2.00      0.11      0.11      0.00      0.00      0.00      0.00
10:07:17 AM     ens33      2.00      2.00      0.12      0.21      0.00      0.00      0.00      0.00
10:07:17 AM     ens37      0.00      2.00      0.00      0.45      0.00      0.00      0.00      0.00
```

Great tool to check network interface throughput, both TX and RX. 

#### sar -n TCP,ETCP 1

```bash
10:08:23 AM  active/s passive/s    iseg/s    oseg/s
10:08:24 AM      0.00      0.00      4.00      4.00

10:08:23 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
10:08:24 AM      0.00      0.00      0.00      0.00      0.00
```

Summary of few TCP metrics. \
For example, `active/s` includes locally-initiated TCP connections per second (`connect`). \
`passive/s` includes passive accepted TCP connections (`accept`). \
Also the retransmission counter is displayed. 

#### top

Probably the best tool for usermode process analysis. \
Contains many metrics for every process within the system. 

### BCC Tools

The tools may be installed on the system, by installing `bcc` from the `apt` servers. \
All tools are located under: `/usr/share/bcc/tools`.

Alternatively, clone the bcc github repo, and under the `tools/` directory of the sources, there are many useful already-written tools, which have a `.py` extension. 

For example, `offcputime.py` is a very usefull tracing tool. \
It allows watching which thread within the system is blocked (for example, because it is waiting for I/O), and the amount of time it was blocked (`re_scheduled_to_CPU_timestamp - blocked_timestamp`). \
Moreover, it displays the stack trace and the task name. 

### General Performance

#### execsnoop

Prints one line of output for each new `exec`'d process. \
It works by tracing the `exec` syscall. 

```bash
# ./execsnoop
PCOMM            PID     PPID    RET ARGS
ls               3434    2668      0 /usr/bin/ls --color=auto -alF
```

#### opensnoop

Prints one line of output for each `open` syscall. \
It also states many details about the process who have opened the file:

```bash
# ./opensnoop -FUTe
TIME(s)       UID   PID    COMM               FD ERR FLAGS    PATH
0.000000000   1000  2246   node               30   0 02000000 /home/itay/.vscode-server/data/User/workspaceStorage/e2e58e40cfee70567f73c1f791424fb7/vscode.lock
0.136810000   108   654    systemd-oomd        7   0 02000000 /proc/meminfo
0.386595000   108   654    systemd-oomd        7   0 02000000 /proc/meminfo
0.418036000   1000  2667   tmux: server       10   0 00000000 /proc/3562/cmdline
0.636830000   108   654    systemd-oomd        7   0 02000000 /proc/meminfo
0.886199000   108   654    systemd-oomd        7   0 02000000 /proc/meminfo
0.887743000   108   654    systemd-oomd        7   0 02000000 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/memory.pressure
0.888919000   108   654    systemd-oomd        7   0 02000000 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/memory.current
0.889695000   108   654    systemd-oomd        7   0 02000000 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/memory.min
0.890368000   108   654    systemd-oomd        7   0 02000000 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/memory.low
0.892240000   108   654    systemd-oomd        7   0 02000000 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/memory.swap.current
0.895803000   108   654    systemd-oomd        7   0 02000000 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/memory.stat
0.919476000   1000  2667   tmux: server       10   0 00000000 /proc/3562/cmdline
```

#### tcpconnect, tcpaccept

Prints line of output for every active TCP connection (issued via `connect`). 

```bash
# ./tcpconnect
PID    COMM         IP SADDR            DADDR            DPORT
1479   telnet       4  127.0.0.1        127.0.0.1        23
1469   curl         4  10.201.219.236   54.245.105.25    80
1469   curl         4  10.201.219.236   54.67.101.145    80
1991   telnet       6  ::1              ::1              23
2015   ssh          6  fe80::2000:bff:fe82:3ac fe80::2000:bff:fe82:3ac 22
```

`tcpaccept` is very similar, just for the `accept` syscall. 

#### runqlat

Traces how long threads were waiting on the CPU run queues. \
Prints an histogram of the threads waiting times:

```bash
usecs               : count     distribution
         0 -> 1          : 2        |                                        |
         2 -> 3          : 28       |******                                  |
         4 -> 7          : 17       |***                                     |
         8 -> 15         : 63       |*************                           |
        16 -> 31         : 40       |********                                |
        32 -> 63         : 45       |*********                               |
        64 -> 127        : 98       |*********************                   |
       128 -> 255        : 181      |****************************************|
       256 -> 511        : 67       |**************                          |
       512 -> 1023       : 16       |***                                     |
      1024 -> 2047       : 11       |**                                      |
      2048 -> 4095       : 2        |                                        |
      4096 -> 8191       : 1        |                                        |
```

This means that on my system, most of the threads were waiting between 128 to 255 usecs on the CPU run queues. 

Recall the CPU run queue is a holding area for threads and processes that require the CPU, when the CPU is busy serving other processes. \
Its length is an indicator of whether the system has sufficient CPU resourecs for all the processes it executes, and can be found via `runqlen`. 

#### profile

This one is very cool - CPU profiler, which takes samples of stack traces at timed interval (Hz), and prints a summary of unique stack traces and a count of their occurrence. 

Note it traces both the users and the kernel stacks, along with kernel functions. 

```bash
# ./profile

Sampling at 49 Hertz of all threads by user + kernel stack... Hit Ctrl-C to end.
^C
    __GI___libc_free
    node::BaseObject::~BaseObject()
    node::AsyncWrap::~AsyncWrap()
    node::fs::FSReqCallback::~FSReqCallback()
    node::fs::FSReqAfterScope::~FSReqAfterScope()
    node::fs::AfterNoArgs(uv_fs_s*)
    uv__work_done
    uv__async_io.part.1
    uv__io_poll
    uv_run
    node::SpinEventLoop(node::Environment*)
    node::NodeMainInstance::Run(node::EnvSerializeInfo const*)
    node::Start(int, char**)
    __libc_start_call_main
    -                node (2246)
        1

    sock_poll
    sock_poll
    do_poll.constprop.0
    do_sys_poll
    __x64_sys_poll
    do_syscall_64
    entry_SYSCALL_64_after_hwframe
    __libc_poll
    [unknown]
    -                vmtoolsd (1611)
        1

    scsi_init_command
    scsi_init_command
    scsi_prepare_cmd
    scsi_queue_rq
    blk_mq_dispatch_rq_list
    __blk_mq_do_dispatch_sched
    blk_mq_do_dispatch_sched
    __blk_mq_sched_dispatch_requests
    blk_mq_sched_dispatch_requests
    __blk_mq_run_hw_queue
    blk_mq_run_work_fn
    process_one_work
    worker_thread
    kthread
    ret_from_fork
    -                kworker/0:1H (198)
        1

    [unknown]
    [unknown]
    -                gnome-shell (1296)
        1

    __lock_text_start
    __lock_text_start
    e1000_update_stats
    e1000_watchdog
    process_one_work
    worker_thread
    kthread
    ret_from_fork
    -                kworker/2:1 (3698)
        2

    mpt_put_msg_frame
    mpt_put_msg_frame
    mptscsih_qcmd
    mptspi_qcmd
    scsi_dispatch_cmd
    scsi_queue_rq
    blk_mq_dispatch_rq_list
    __blk_mq_do_dispatch_sched
    blk_mq_do_dispatch_sched
    __blk_mq_sched_dispatch_requests
    blk_mq_sched_dispatch_requests
    __blk_mq_run_hw_queue
    blk_mq_run_work_fn
    process_one_work
    worker_thread
    kthread
    ret_from_fork
    -                kworker/0:1H (198)
        2
```

The number in parenthesis describes the PID. \
The integer at the following line counts how many times this stack trace was sampled. 

This tool is very handy in order to understand code paths that are consuming CPU resources. \
The sampling frequency may be increased via `-F`, and may be bound to a specific core via `-C`. \
It is also possible to trace only a specific process, via `./profile -p PID`. 

Lastly, folded format may be used (`-f`) in order to output the stack trace on one line, which can be used by flame graph stack visualizers. 

### BCC Generic Tools

There are generic tools that can provide visibility. 

#### trace

Can be served as generic function tracer. \
In particular, this may come handy for syscall tracing:

```bash
$ trace.py \
  'p::SyS_chown "file = %s, to_uid = %d, to_gid = %d, from_uid = %d", arg1, arg2, arg3, $uid' \
  'p::SyS_fchown "fd = %d, to_uid = %d, to_gid = %d, from_uid = %d", arg1, arg2, arg3, $uid' \
  'p::SyS_lchown "file = %s, to_uid = %d, to_gid = %d, from_uid = %d", arg1, arg2, arg3, $uid'
```

Another examples:

```bash
# Trace returns from open syscall, and print its retval 
trace 'r::do_sys_open "%llx", retval'  
# Trace malloc library calls
trace 'c:malloc "size = %d", arg1'  
# Trace the block kernel tracepoint, print its argument
trace 't:block:block_rq_complete "sectors=%d", args->nr_sector' 
# Trace USDT (user-statically-defined-tracing) probe 
trace 'u:pthread:pthread_create (arg4 != 0)'
# Trace syscall, parse its struct argument
trace 'p::SyS_nanosleep(struct timespec *ts) "sleep for %lld ns", ts->tv_nsec'
# Include extra header to the BPF program. Trace sendmsg calls for BE dest port 53. 
trace -I 'net/sock.h' 'udpv6_sendmsg(struct sock *sk) (sk->sk_dport == 13568)'
```

Extra reading: [usdt-probes][usdt-probes]

#### argdist

Can be used to display an histogram of the argument values of the probed function. \
For example, visualize allocation sizes histogram, as probed by `malloc` calls. 

#### funccount

Prints summary of function call count.

For example:

```bash
# ./funccount 'vfs_*'
^C
FUNC                          COUNT
vfs_create                        1
vfs_rename                        1
vfs_fsync_range                   2
vfs_lock_file                    30
vfs_fstatat                     152
vfs_fstat                       154
vfs_write                       166
vfs_getattr_nosec               262
vfs_getattr                     262
vfs_open                        264
vfs_read                        470
```

[bcc-git]: https://github.com/iovisor/bcc
[link0]: https://www.iovisor.org/technology/bcc
[link1]: https://opensource.com/article/17/11/bccbpf-performance
[link2]: https://www.redhat.com/en/blog/bcc-tools-brings-dynamic-kernel-tracing-red-hat-enterprise-linux-81
[link3]: https://www.containiq.com/post/bcc-tools
[linux-performance]: https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55
[free-confusion]: https://www.linuxatemyram.com/
[more-performance]: https://netflixtechblog.com/netflix-at-velocity-2015-linux-performance-tools-51964ddb81cf
[usdt-probes]: https://lwn.net/Articles/753601/
